[
    "Load every CSV in the 'State MSA Identity Theft data' folder, trimming blank lines.",
    "Strip commas, dollar signs and suffixes (K, M) so '# of Reports' becomes numeric.",
    "Vertically concatenate the cleaned state-level CSV frames into one dataframe (df_reports).",
    "Open metropolitan_statistics.html, locate the table titled like 'The 387 metropolitan statistical areas of the United States', and read it into a dataframe (df_population).",
    "Create an estimated 2023 population for each metro by linearly interpolating between the 2020 census and the 2024 estimate: pop_2023 = 2020 + (3\u20444)*(2024 \u2212 2020).",
    "Normalizing the metro name column, by lower casing, removing the suffixes 'Metropolitan Statistical Area' or 'MSA', then stripping all non-alphanumeric characters.",
    "Inner join on msa_key so only metros present in both the fraud and population sources are retained (dropping unmatched entries automatically).",
    "Compute the identity-theft rate per 100 000 residents: fraud_per_100k = (# of Reports / interpolated_2023_population) * 100 000.",
    "Select the row whose fraud_per_100k is maximal and print its original \u2018Metropolitan Area\u2019 name; this is the metro with the highest identity-theft rate."
]